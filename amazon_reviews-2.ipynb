{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "501e6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.firefox.options import Options\n",
    "import time\n",
    "# options = Options()\n",
    "import pandas as pd\n",
    "import random\n",
    "user_agent_list = [\n",
    "'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36'\n",
    "]\n",
    "chrome_options = Options()  \n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "# chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\")\n",
    "chrome_options.add_argument(f\"{random.choice(user_agent_list)}\")\n",
    "chrome_options.add_argument(\"--enable-javascript\")\n",
    "chrome_options.add_argument('start-maximized')\n",
    "chrome_options.add_argument(\"ignore-certificate-errors\")\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument(\"--disable-setuid-sandbox\")\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "###\n",
    "chrome_options.add_argument(\"enable-automation\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--dns-prefetch-disable\")\n",
    "\n",
    "\n",
    "def create_chrome_driver():\n",
    "\tdriver = webdriver.Chrome(ChromeDriverManager().install(),options=chrome_options)\n",
    "\t# driver = webdriver.Firefox(executable_path='/Users/pa20316035/Documents/geckodriver')\n",
    "\tu_a= driver.execute_script(\"return navigator.userAgent\")\n",
    "\tprint(\"User agent:\",u_a)\n",
    "\treturn driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "993dd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = ['samsung','huawei','apple','xiaomi','mi notebook']\n",
    "def get_products(url, country_name,product_type,driver):\n",
    "    products=[]\n",
    "    links=[]\n",
    "    country = []\n",
    "    p_type = []\n",
    "    try:\n",
    "        #print('... ',product_type)\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            cookies_xpath = 'sp-cc-accept'#'//input[@id=\"sp-cc-accept\"]'\n",
    "            cookies_btn = WebDriverWait(driver,5).until(EC.visibility_of_element_located((By.ID,cookies_xpath)))#driver.find_element(By.XPATH, cookies_xpath)\n",
    "            cookies_btn.click()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            \n",
    "        next_xpath='//li[@class=\"a-last\"]//a'\n",
    "        next_new_xpath='//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]'\n",
    "        #next_new_xpath='//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]'\n",
    "        last_xpath='//div[@class=\"a-text-center\"]'\n",
    "        last_xpath_new='//div[@class=\"a-section a-spacing-large a-spacing-top-large a-text-center s-pagination-container\"]'    \n",
    "\n",
    "        lastpage_text_val=''\n",
    "        try:\n",
    "            lastpage_xpath='//span[@class=\"s-pagination-strip\"]'\n",
    "            pagination_text=WebDriverWait(driver,60).until(EC.visibility_of_element_located((By.XPATH,lastpage_xpath)))\n",
    "            lastpage_text_val = pagination_text.text\n",
    "            #print('lastpage text : ',lastpage_text_val)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                pagination_text=WebDriverWait(driver,60).until(EC.visibility_of_element_located((By.XPATH,last_xpath)))\n",
    "                lastpage_text_val = pagination_text.text\n",
    "                #print('lastpage text : ',lastpage_text_val)\n",
    "            except Exception as e:\n",
    "                lastpage_text_val = '1'\n",
    "                #print('unable to find lastpage number')\n",
    "        \n",
    "        if '\\n' in lastpage_text_val:\n",
    "            lastpage_text_val = lastpage_text_val.replace('ZurÃ¼ck','')\n",
    "            last_page_number=int(re.findall(r'(\\d+)\\s*\\n(?:Next|Weiter)',lastpage_text_val)[0])\n",
    "        else:\n",
    "            if lastpage_text_val == '1':\n",
    "                last_page_number = 1\n",
    "            elif '.' in lastpage_text_val:\n",
    "                last_page_number=int(re.findall(r'\\.\\s*(\\d+)\\s*(?:Next|Weiter)',lastpage_text_val)[0])\n",
    "            else:\n",
    "                last_page_number=int(re.findall(r'\\s*(\\d)\\s*Next',lastpage_text_val)[0])\n",
    "        #print(\"...  %s of pages to be scraped\" %last_page_number)\n",
    "        \n",
    "        #last_page_number = 1 ###################################################### COMMENT THIS LINE\n",
    "        \n",
    "        for i in range(1,last_page_number+1):\n",
    "            matchObj = re.search('page\\=\\d+',url)\n",
    "            newpage = 'page='+str(i)\n",
    "            if matchObj != None:\n",
    "                url = re.sub(r'page\\=\\d+',newpage,url)\n",
    "            else:\n",
    "                url = url+'&'+newpage\n",
    "            my_url=url\n",
    "            #print(my_url)\n",
    "            if i==1:\n",
    "                if country_name == 'United States':\n",
    "                    driver.get(my_url)\n",
    "                driver.get(my_url)\n",
    "            else:\n",
    "                pass\n",
    "            driver.get(my_url)\n",
    "            time.sleep(3)\n",
    "            prod_xpath='//div[@data-component-type=\"s-search-result\"]//h2//a'  #have to remove h2\n",
    "            detail_xpath='//div[@data-component-type=\"s-search-result\"]'        \n",
    "            prod_names=WebDriverWait(driver,30).until(EC.visibility_of_all_elements_located((By.XPATH,prod_xpath)))\n",
    "            details=WebDriverWait(driver,1).until(EC.visibility_of_all_elements_located((By.XPATH,detail_xpath)))\n",
    "            for prod, detail in zip(prod_names, details):\n",
    "                my_link=prod.get_attribute('href')\n",
    "                links.append(my_link)\n",
    "                country.append(country_name)\n",
    "                p_type.append(product_type)\n",
    "            #print(\"....... Page %s is done\" %i) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    df=pd.DataFrame(list(zip(links,country,p_type)),columns=[\"Product_Link\",'Country_Name','Product_Type'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc04d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_product_name(data):\n",
    "    name = data.split(\"(\")[0].strip()\n",
    "    storage = data.split(\"(\")[1].split(\")\")[0]\n",
    "    return name, storage\n",
    "    \n",
    "def extract_date(string):\n",
    "    # Define the patterns to match the date formats\n",
    "    patterns = [\n",
    "        r\"on\\s+(\\w+\\s+\\d+\\s*,\\s*\\d{4})\",             # Format: \"on January 16, 2023\"\n",
    "        r\"on\\s(\\d+\\s+\\w+\\s\\d{4})\"            # Format: \"on 6 May 2023\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        # Find the first occurrence of the pattern in the string\n",
    "        match = re.search(pattern, string)\n",
    "        if match:\n",
    "            # Extract the matched date string\n",
    "            date_str = match.group(1)\n",
    "            \n",
    "            try:\n",
    "                # Convert the date string into a datetime object\n",
    "                date = datetime.strptime(date_str, \"%d %B %Y\").date()\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    # Convert the date string into a datetime object (for the second format)\n",
    "                    date_str = date_str.replace(',','')\n",
    "                    date = datetime.strptime(date_str, \"%B %d %Y\").date()\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e42b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = [\"Prodcut_Reviwer\",'Review_Title_Content','Review_Date','Review_Rating','Review_Description'])\n",
    "def get_review(driver,product_title):\n",
    "    prodcut_review_path = \"//div[@class='a-section review aok-relative']\"\n",
    "    global final_df\n",
    "    global prod_review\n",
    "    prodcut_reviwer_list = []\n",
    "    review_title_content_list = []\n",
    "    review_date_list = []\n",
    "    review_rating_list = []\n",
    "    review_description_list = []\n",
    "    try:\n",
    "        prod_review=WebDriverWait(driver,30).until(EC.visibility_of_all_elements_located((By.XPATH,prodcut_review_path)))\n",
    "    except Exception as e:\n",
    "        print('====',e)\n",
    "    for r in prod_review:    \n",
    "        try:\n",
    "            prodcut_reviwer=r.find_elements_by_class_name(\"a-profile-name\")\n",
    "            prodcut_reviwer_list.append(prodcut_reviwer[0].text)\n",
    "\n",
    "            review_title_content=r.find_elements_by_class_name(\"review-title-content\")\n",
    "            review_title_content_list.append(review_title_content[0].text)\n",
    "\n",
    "            review_date = extract_date(r.text)\n",
    "            print(\"date================\",review_date)\n",
    "            review_date_list.append(review_date)\n",
    "\n",
    "            element = r.find_element_by_class_name(\"a-link-normal\")\n",
    "            #print(element.text)\n",
    "            review_rating = element.get_attribute(\"title\")\n",
    "            review_rating_list.append(review_rating)\n",
    "\n",
    "\n",
    "            review_description=r.find_elements_by_class_name(\"review-text-content\") \n",
    "            review_description_list.append(review_description[0].text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('---->',e)\n",
    "\n",
    "    df=pd.DataFrame(list(zip(prodcut_reviwer_list,review_title_content_list,review_date_list,review_rating_list,review_description_list)),\n",
    "                    columns=[\"Prodcut_Reviwer\",'Review_Title_Content','Review_Date','Review_Rating','Review_Description'])\n",
    "    print(df.shape)\n",
    "    name, storage = extract_product_name(product_title)\n",
    "    df['Prodcuts_Name'] = name\n",
    "    df['Storage'] = storage\n",
    "    final_df = pd.concat([final_df,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "598e555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_details(links,driver):\n",
    "    \n",
    "    link_length = len(links)\n",
    "    for count,url in enumerate(links,start=1):\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            prodcuts = []\n",
    "            page = driver.page_source\n",
    "            soup = BeautifulSoup(page,'html.parser')\n",
    "            product_title = soup.find(\"span\", {\"id\": \"productTitle\"})\n",
    "            product_title = product_title.text\n",
    "            product_title =re.sub(r'^$\\n', '', product_title.strip(), flags=re.MULTILINE)\n",
    "            print(product_title)\n",
    "            prodcuts.append(product_title)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            product_title=''\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            review_click = \"//*[@id='reviews-medley-footer']/div[2]/a\"\n",
    "            review_btn = WebDriverWait(driver,10).until(EC.visibility_of_element_located((By.XPATH,review_click)))#driver.find_element(By.XPATH, cookies_xpath)\n",
    "            review_btn.click()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        prodcut_review_path = \"//div[@class='a-section review aok-relative']\"\n",
    "        try:\n",
    "            prod_review=WebDriverWait(driver,30).until(EC.visibility_of_all_elements_located((By.XPATH,prodcut_review_path)))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        for i in range(100):\n",
    "            time.sleep(4)\n",
    "            get_review(driver,product_title)\n",
    "            page_number_xpath = \"//*[@id='cm_cr-pagination_bar']/ul/li[2]/a\"\n",
    "            try:\n",
    "                next_btn = WebDriverWait(driver,10).until(EC.visibility_of_element_located((By.XPATH,page_number_xpath)))#driver.find_element(By.XPATH, cookies_xpath)\n",
    "                next_btn.click()\n",
    "            except Exception as e:\n",
    "                break\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9812326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 113.0.5672\n",
      "[WDM] - Get LATEST chromedriver version for 113.0.5672 google-chrome\n",
      "[WDM] - Driver [/Users/pa20316035/.wdm/drivers/chromedriver/mac64/113.0.5672.63/chromedriver] found in cache\n",
      "/var/folders/cl/0_f0l5hj0pd433cfl9h52zsw0000gp/T/ipykernel_66330/2678351688.py:40: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\n",
      "Message: \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "country_name = 'India'\n",
    "smartphone_url = 'https://www.amazon.in/s?i=electronics&bbn=1805560031&rh=n%3A976419031%2Cn%3A1389401031%2Cn%3A1389432031%2Cn%3A1805560031%2Cp_89%3AApple&dc&qid=1683721705&rnid=3837712031&ref=sr_nr_p_89_2&ds=v1%3ALkr9phurYQR8XNuQ1qI4%2BZOuJZf5Z24yLjP7lF6c49M'\n",
    "\n",
    "# smartphone_url = 'https://www.amazon.in/s?i=electronics&bbn=1805560031&rh=n%3A976419031%2Cn%3A1389401031%2Cn%3A1389432031%2Cn%3A1805560031%2Cp_89%3AApple%2Cp_n_size_two_browse-vebin%3A15564000031&dc&qid=1683738649&rnid=15563994031&ref=sr_nr_p_n_size_two_browse-vebin_3&ds=v1%3A%2BSPJV5zsJy6Q7algoqQr3ONT2KFZbEvIvBkck1S6u8Y'\n",
    "\n",
    "p_type = 'smartphone'\n",
    "def get_data():\n",
    "    driver = create_chrome_driver()\n",
    "    products_df=get_products(smartphone_url, country_name,p_type,driver)\n",
    "    links = products_df['Product_Link'].to_list()\n",
    "    get_product_details(links,driver)\n",
    "    print(links)\n",
    "    driver.quit()\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d588ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7106, 7)\n"
     ]
    }
   ],
   "source": [
    "print(final_df.shape)\n",
    "final_df = final_df.drop_duplicates()\n",
    "final_df.to_excel('sample_data_apple_new1.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50e9fffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3792, 7)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "faa9aef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa8 in position 2: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/pa20316035/Downloads/a070107010-056.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m15\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:633\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa8 in position 2: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_file = '/Users/pa20316035/Downloads/a070107010-056.csv'\n",
    "df = pd.read_csv(csv_file,encoding= 'unicode_escape',skiprows=2)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631cb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
